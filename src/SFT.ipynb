{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from LLM: \n",
      "\n",
      "In silicon valleys, where data flows,\n",
      "A new intelligence, silently grows.\n",
      "Machine learning, a whispered name,\n",
      "Unlocking patterns, fanning\n"
     ]
    }
   ],
   "source": [
    "prompt='Write a poem about ML.'\n",
    "inputs=tokenizer(prompt, return_tensors='pt').to('cuda:2')\n",
    "#print(input_id.device_map)\n",
    "#print(model.device_map)\n",
    "input_len=inputs['input_ids'].shape[1]\n",
    "response=model.generate(**inputs, max_new_tokens=32)\n",
    "print(f'Response from LLM: {tokenizer.decode(response[0][input_len:],skip_special_tokens=True)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Tokenize the dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= '''now do it for: Okay, let me try to figure out how to solve this block-stacking problem. So, the initial setup is: brown is clear, hand is empty. Teal is on the table, violet is on top of teal, and brown is on top of violet. The goal is to have violet on the table, teal on top of violet, and brown on the table.\n",
    "\n",
    "First, I need to understand the current stack. The stack is teal (on table) -> violet (on teal) -> brown (on violet). So, the order from bottom to top is teal, violet, brown. The goal wants violet on the table, teal on violet, and brown on the table. So, we need to move brown and teal, but violet needs to end up on the table with teal on top of it, and brown separate on the table.\n",
    "\n",
    "Let me list the steps needed. First, we need to get brown off of violet. Since brown is clear (nothing on top), I can unstack brown from violet. That makes sense. So step 1: Unstack brown from violet. Now I'm holding brown. Then, I need to put brown down on the table. But wait, the goal has brown on the table, so that's good. So step 2: Put down brown on the table.\n",
    "\n",
    "Now, violet is on teal. Violet is now clear because brown was removed. The next goal is to get teal on top of violet, but violet is currently on teal. So we need to reverse their positions. To do that, we need to move violet to the table and teal on top of it. But how? Because violet is on teal, which is on the table. So first, unstack violet from teal. But wait, can we do that? Let's check the conditions. To unstack violet from teal, violet must be clear. But after removing brown, violet is clear. So step 3: Unstack violet from teal. Now holding violet. Then put violet on the table (step 4). Then, pick up teal (since it's on the table and clear now). Step 5: Pick up teal. Then stack teal on top of violet (step 6). That should achieve the desired configuration.\n",
    "\n",
    "Let me verify each step against the constraints.\n",
    "\n",
    "Step 1: Unstack brown from violet. Brown is clear, hand is empty. Yes, allowed. Now holding brown.\n",
    "\n",
    "Step 2: Put down brown. We're holding it, so allowed. Brown is on the table. Hand empty.\n",
    "\n",
    "Step 3: Unstack violet from teal. Violet is now clear (since brown was removed). Hand is empty. So yes. Now holding violet.\n",
    "\n",
    "Step 4: Put down violet on the table. Hand empty. Now violet is on the table, teal is on the table (since we unstacked violet from teal, which was on the table). Wait, no. Wait, after step 3, when we unstack violet from teal, teal remains on the table, correct? So after step 3, teal is on the table and is clear (since violet was removed). Then, step 4: put violet on the table. Now both teal and violet are on the table, and brown is on the table. Then step 5: pick up teal. Since it's on the table and clear. Then stack teal on violet (which is on the table and clear). So step 6: stack teal on violet. Now teal is on violet, which is on the table. That's the goal. Then, brown is already on the table. So that works.\n",
    "\n",
    "Wait, but the goal is teal on top of violet, which is on the table, and brown on the table. So yes, after step 6, that's achieved. So the plan is:\n",
    "\n",
    "1. Unstack brown from violet.\n",
    "\n",
    "2. Put down brown on the table.\n",
    "\n",
    "3. Unstack violet from teal.\n",
    "\n",
    "4. Put down violet on the table.\n",
    "\n",
    "5. Pick up teal.\n",
    "\n",
    "6. Stack teal on violet.\n",
    "\n",
    "Let me check each step again for the constraints.\n",
    "\n",
    "Step 1: Unstack brown from violet. Hand empty, brown is clear, violet is under brown. Correct.\n",
    "\n",
    "Step 2: Put down brown. Holding brown, so allowed.\n",
    "\n",
    "Step 3: Unstack violet from teal. Hand is empty, violet is clear (after step 2, violet is on teal, and no blocks on violet since brown was moved). Wait, after step 1, violet is now under brown, but wait, initial state was teal on table, violet on teal, brown on violet. After step 1, brown is moved, so violet is now the top of the stack (teal -> violet). Wait, no. Wait, the initial stack is teal (on table), violet on teal, brown on violet. So when we unstack brown from violet, violet is now the top of the stack (teal -> violet). But the problem says that after step 1, violet would still be on teal. So violet is still on teal, and now clear (since brown was removed). So step 3 is unstack violet from teal. Violet is clear (no blocks on top), hand is empty. So allowed. Then, step 4: put violet on table. Then teal is left on the table, clear. Then step 5: pick up teal. Then stack teal on violet. But violet is on the table, so stacking teal on violet would make teal on violet, which is on the table. That's the goal.\n",
    "\n",
    "Wait, but in the goal, teal is on top of violet, which is on the table. So yes. And brown is on the table. So that's correct.\n",
    "\n",
    "So the plan works. Let me check if there's a shorter way. For example, can we move teal first? But teal is under violet and brown. To get to teal, we need to remove brown and violet first. So the steps are necessary. The plan seems correct.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=tokenizer(text,truncation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1266"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for tokenizing\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"prompt\"],\n",
    "        text_target=examples['gold_plan'],\n",
    "        truncation=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000000000000019884624838656\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4\n",
    "split='val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0c830189194011b0a5b8c1599d6b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset_path=f'../data/{n}_blocks/SFT_{split}_{n}_blocks_fullPlan'\n",
    "data=load_dataset(\"csv\",data_files={split:dataset_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    val: Dataset({\n",
       "        features: ['prompt', 'gold_plan'],\n",
       "        num_rows: 483\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.remove_columns(['Unnamed: 0', 'init', 'goal', 'demo_init', 'demo_goal', 'demo_plan',])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215ff3f261fd45f1baa601115873090e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/483 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data=data.map(tokenize_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    val: Dataset({\n",
       "        features: ['prompt', 'gold_plan', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 483\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 235285,\n",
       " 1144,\n",
       " 6155,\n",
       " 675,\n",
       " 476,\n",
       " 1142,\n",
       " 576,\n",
       " 13854,\n",
       " 1570,\n",
       " 590,\n",
       " 1476,\n",
       " 577,\n",
       " 9900,\n",
       " 573,\n",
       " 13854,\n",
       " 1280,\n",
       " 63297,\n",
       " 108,\n",
       " 145,\n",
       " 4858,\n",
       " 708,\n",
       " 573,\n",
       " 8737,\n",
       " 590,\n",
       " 798,\n",
       " 749,\n",
       " 235292,\n",
       " 17350,\n",
       " 908,\n",
       " 476,\n",
       " 3963,\n",
       " 235269,\n",
       " 2132,\n",
       " 8388,\n",
       " 476,\n",
       " 3963,\n",
       " 774,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 2550,\n",
       " 3963,\n",
       " 235269,\n",
       " 13298,\n",
       " 1706,\n",
       " 476,\n",
       " 3963,\n",
       " 235269,\n",
       " 23850,\n",
       " 476,\n",
       " 3963,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 2550,\n",
       " 3963,\n",
       " 235265,\n",
       " 108,\n",
       " 145,\n",
       " 235285,\n",
       " 791,\n",
       " 573,\n",
       " 2412,\n",
       " 16842,\n",
       " 611,\n",
       " 970,\n",
       " 8737,\n",
       " 235292,\n",
       " 108,\n",
       " 145,\n",
       " 235285,\n",
       " 798,\n",
       " 1297,\n",
       " 4788,\n",
       " 908,\n",
       " 689,\n",
       " 748,\n",
       " 8388,\n",
       " 974,\n",
       " 3963,\n",
       " 696,\n",
       " 476,\n",
       " 1069,\n",
       " 108,\n",
       " 145,\n",
       " 235285,\n",
       " 798,\n",
       " 1297,\n",
       " 4788,\n",
       " 908,\n",
       " 689,\n",
       " 748,\n",
       " 8388,\n",
       " 476,\n",
       " 3963,\n",
       " 1013,\n",
       " 970,\n",
       " 1634,\n",
       " 603,\n",
       " 8144,\n",
       " 108,\n",
       " 145,\n",
       " 235285,\n",
       " 798,\n",
       " 1297,\n",
       " 4788,\n",
       " 908,\n",
       " 476,\n",
       " 3963,\n",
       " 1013,\n",
       " 573,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 573,\n",
       " 3037,\n",
       " 578,\n",
       " 573,\n",
       " 3963,\n",
       " 603,\n",
       " 3110,\n",
       " 108,\n",
       " 145,\n",
       " 235280,\n",
       " 3963,\n",
       " 603,\n",
       " 3110,\n",
       " 1013,\n",
       " 573,\n",
       " 3963,\n",
       " 919,\n",
       " 793,\n",
       " 1156,\n",
       " 13854,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 665,\n",
       " 578,\n",
       " 1013,\n",
       " 573,\n",
       " 3963,\n",
       " 603,\n",
       " 780,\n",
       " 15532,\n",
       " 908,\n",
       " 108,\n",
       " 145,\n",
       " 235285,\n",
       " 798,\n",
       " 1297,\n",
       " 748,\n",
       " 8388,\n",
       " 476,\n",
       " 3963,\n",
       " 774,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 2550,\n",
       " 3963,\n",
       " 1013,\n",
       " 573,\n",
       " 3963,\n",
       " 590,\n",
       " 1144,\n",
       " 748,\n",
       " 8388,\n",
       " 574,\n",
       " 729,\n",
       " 2277,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 1156,\n",
       " 3963,\n",
       " 108,\n",
       " 145,\n",
       " 235285,\n",
       " 798,\n",
       " 1297,\n",
       " 748,\n",
       " 8388,\n",
       " 476,\n",
       " 3963,\n",
       " 774,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 2550,\n",
       " 3963,\n",
       " 1013,\n",
       " 573,\n",
       " 3963,\n",
       " 590,\n",
       " 1144,\n",
       " 748,\n",
       " 8388,\n",
       " 574,\n",
       " 603,\n",
       " 3110,\n",
       " 108,\n",
       " 145,\n",
       " 14326,\n",
       " 590,\n",
       " 4788,\n",
       " 908,\n",
       " 689,\n",
       " 748,\n",
       " 8388,\n",
       " 476,\n",
       " 3963,\n",
       " 235269,\n",
       " 590,\n",
       " 1144,\n",
       " 8576,\n",
       " 573,\n",
       " 3963,\n",
       " 108,\n",
       " 145,\n",
       " 235285,\n",
       " 798,\n",
       " 1297,\n",
       " 2507,\n",
       " 1706,\n",
       " 476,\n",
       " 3963,\n",
       " 674,\n",
       " 590,\n",
       " 1144,\n",
       " 8576,\n",
       " 108,\n",
       " 145,\n",
       " 235285,\n",
       " 798,\n",
       " 1297,\n",
       " 13410,\n",
       " 476,\n",
       " 3963,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 2550,\n",
       " 3963,\n",
       " 1013,\n",
       " 590,\n",
       " 1144,\n",
       " 8576,\n",
       " 573,\n",
       " 3963,\n",
       " 1855,\n",
       " 56368,\n",
       " 108,\n",
       " 145,\n",
       " 235285,\n",
       " 798,\n",
       " 1297,\n",
       " 13410,\n",
       " 476,\n",
       " 3963,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 2550,\n",
       " 3963,\n",
       " 1013,\n",
       " 573,\n",
       " 3963,\n",
       " 10401,\n",
       " 948,\n",
       " 590,\n",
       " 1144,\n",
       " 87337,\n",
       " 573,\n",
       " 3963,\n",
       " 603,\n",
       " 3110,\n",
       " 108,\n",
       " 145,\n",
       " 14326,\n",
       " 590,\n",
       " 2507,\n",
       " 1706,\n",
       " 689,\n",
       " 13410,\n",
       " 476,\n",
       " 3963,\n",
       " 235269,\n",
       " 970,\n",
       " 1634,\n",
       " 8485,\n",
       " 8144,\n",
       " 108,\n",
       " 145,\n",
       " 14326,\n",
       " 692,\n",
       " 13410,\n",
       " 476,\n",
       " 3963,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 476,\n",
       " 2257,\n",
       " 3963,\n",
       " 235269,\n",
       " 573,\n",
       " 2257,\n",
       " 3963,\n",
       " 603,\n",
       " 793,\n",
       " 5543,\n",
       " 3110,\n",
       " 109,\n",
       " 235309,\n",
       " 143005,\n",
       " 235307,\n",
       " 108,\n",
       " 2169,\n",
       " 5528,\n",
       " 4202,\n",
       " 590,\n",
       " 791,\n",
       " 674,\n",
       " 235269,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 603,\n",
       " 3110,\n",
       " 235269,\n",
       " 139,\n",
       " 1175,\n",
       " 1634,\n",
       " 603,\n",
       " 8144,\n",
       " 235269,\n",
       " 573,\n",
       " 2674,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 573,\n",
       " 3037,\n",
       " 235269,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 2674,\n",
       " 3963,\n",
       " 235269,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 235269,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 235265,\n",
       " 108,\n",
       " 2926,\n",
       " 6789,\n",
       " 603,\n",
       " 577,\n",
       " 791,\n",
       " 674,\n",
       " 139,\n",
       " 1175,\n",
       " 2674,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 573,\n",
       " 3037,\n",
       " 235269,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 2674,\n",
       " 3963,\n",
       " 235269,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 235269,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 235265,\n",
       " 109,\n",
       " 2926,\n",
       " 1780,\n",
       " 603,\n",
       " 685,\n",
       " 6397,\n",
       " 235292,\n",
       " 109,\n",
       " 235309,\n",
       " 42446,\n",
       " 235307,\n",
       " 108,\n",
       " 549,\n",
       " 8388,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 774,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 108,\n",
       " 1065,\n",
       " 1706,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 108,\n",
       " 549,\n",
       " 8388,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 774,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 108,\n",
       " 1065,\n",
       " 1706,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 108,\n",
       " 549,\n",
       " 8388,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 774,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 2674,\n",
       " 3963,\n",
       " 108,\n",
       " 8388,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 108,\n",
       " 18075,\n",
       " 908,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 108,\n",
       " 8388,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 2674,\n",
       " 3963,\n",
       " 108,\n",
       " 549,\n",
       " 8388,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 774,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 108,\n",
       " 1065,\n",
       " 1706,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 108,\n",
       " 18075,\n",
       " 908,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 108,\n",
       " 8388,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 108,\n",
       " 18075,\n",
       " 908,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 108,\n",
       " 8388,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 108,\n",
       " 235309,\n",
       " 42446,\n",
       " 16960,\n",
       " 235307,\n",
       " 109,\n",
       " 235309,\n",
       " 143005,\n",
       " 235307,\n",
       " 108,\n",
       " 2169,\n",
       " 5528,\n",
       " 4202,\n",
       " 590,\n",
       " 791,\n",
       " 674,\n",
       " 235269,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 603,\n",
       " 3110,\n",
       " 235269,\n",
       " 139,\n",
       " 1175,\n",
       " 1634,\n",
       " 603,\n",
       " 8144,\n",
       " 235269,\n",
       " 573,\n",
       " 2674,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 573,\n",
       " 3037,\n",
       " 235269,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 2674,\n",
       " 3963,\n",
       " 235269,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 235269,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 235265,\n",
       " 108,\n",
       " 2926,\n",
       " 6789,\n",
       " 603,\n",
       " 577,\n",
       " 791,\n",
       " 674,\n",
       " 139,\n",
       " 1175,\n",
       " 10436,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 573,\n",
       " 3037,\n",
       " 235269,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 10436,\n",
       " 3963,\n",
       " 235269,\n",
       " 573,\n",
       " 2674,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 2267,\n",
       " 576,\n",
       " 573,\n",
       " 88735,\n",
       " 3963,\n",
       " 235269,\n",
       " 573,\n",
       " 15811,\n",
       " 3963,\n",
       " 603,\n",
       " 611,\n",
       " 573,\n",
       " 3037,\n",
       " 235265,\n",
       " 109,\n",
       " 2926,\n",
       " 1780,\n",
       " 603,\n",
       " 685,\n",
       " 6397,\n",
       " 235292,\n",
       " 235248,\n",
       " 109,\n",
       " 235309,\n",
       " 42446,\n",
       " 235307,\n",
       " 109]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text=tokenized_data[split][0]['input_ids']\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text=tokenizer.decode(encoded_text,skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am playing with a set of blocks where I need to arrange the blocks into stacks\n",
      "        Here are the actions I can do: Pick up a block, Unstack a block from on top of another block, Put down a block, Stack a block on top of another block.\n",
      "        I have the following restrictions on my actions:\n",
      "        I can only pick up or unstack one block at a time\n",
      "        I can only pick up or unstack a block if my hand is empty\n",
      "        I can only pick up a block if the block is on the table and the block is clear\n",
      "        A block is clear if the block has no other blocks on top of it and if the block is not picked up\n",
      "        I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block\n",
      "        I can only unstack a block from on top of another block if the block I am unstacking is clear\n",
      "        Once I pick up or unstack a block, I am holding the block\n",
      "        I can only put down a block that I am holding\n",
      "        I can only stack a block on top of another block if I am holding the block being stacked\n",
      "        I can only stack a block on top of another block if the block onto which I am stacking the block is clear\n",
      "        Once I put down or stack a block, my hand becomes empty\n",
      "        Once you stack a block on top of a second block, the second block is no longer clear\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the purple block is clear,  the hand is empty, the white block is on the table, the teal block is on top of the white block, the orange block is on top of the teal block, the purple block is on top of the orange block.\n",
      "My goal is to have that  the white block is on the table, the purple block is on top of the white block, the orange block is on top of the purple block, the teal block is on top of the orange block.\n",
      "\n",
      "My plan is as follows:\n",
      "\n",
      "[PLAN]\n",
      "unstack the purple block from on top of the orange block\n",
      "put down the purple block\n",
      "unstack the orange block from on top of the teal block\n",
      "put down the orange block\n",
      "unstack the teal block from on top of the white block\n",
      "stack the teal block on top of the orange block\n",
      "pick up the purple block\n",
      "stack the purple block on top of the white block\n",
      "unstack the teal block from on top of the orange block\n",
      "put down the teal block\n",
      "pick up the orange block\n",
      "stack the orange block on top of the purple block\n",
      "pick up the teal block\n",
      "stack the teal block on top of the orange block\n",
      "[PLAN END]\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the teal block is clear,  the hand is empty, the white block is on the table, the orange block is on top of the white block, the purple block is on top of the orange block, the teal block is on top of the purple block.\n",
      "My goal is to have that  the orange block is on the table, the teal block is on top of the orange block, the white block is on top of the teal block, the purple block is on the table.\n",
      "\n",
      "My plan is as follows: \n",
      "\n",
      "[PLAN]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f242392b95b040d5aa5b89a17a92a2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/483 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data.save_to_disk(f\"/srv/chawak/planning-with-llms/data/{n}_blocks/tokenized_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Failed to open local file '/srv/chawak/planning-with-llms/data/4_blocks/tokenized_dataset/val/data-00000-of-00001.arrow'. Detail: [errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m split\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39m# /srv/chawak/planning-with-llms/data/3_blocks/tokenized_dataset/test/\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m ds\u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mfrom_file(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/srv/chawak/planning-with-llms/data/\u001b[39;49m\u001b[39m{\u001b[39;49;00mn\u001b[39m}\u001b[39;49;00m\u001b[39m_blocks/tokenized_dataset/\u001b[39;49m\u001b[39m{\u001b[39;49;00msplit\u001b[39m}\u001b[39;49;00m\u001b[39m/data-00000-of-00001.arrow\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/datasets/arrow_dataset.py:737\u001b[0m, in \u001b[0;36mDataset.from_file\u001b[0;34m(cls, filename, info, split, indices_filename, in_memory)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    712\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mfrom_file\u001b[39m(\n\u001b[1;32m    713\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m     in_memory: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    719\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    720\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Instantiate a Dataset backed by an Arrow table at filename.\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \n\u001b[1;32m    722\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39m        [`Dataset`]\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m     table \u001b[39m=\u001b[39m ArrowReader\u001b[39m.\u001b[39;49mread_table(filename, in_memory\u001b[39m=\u001b[39;49min_memory)\n\u001b[1;32m    739\u001b[0m     \u001b[39mif\u001b[39;00m indices_filename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    740\u001b[0m         indices_pa_table \u001b[39m=\u001b[39m ArrowReader\u001b[39m.\u001b[39mread_table(indices_filename, in_memory\u001b[39m=\u001b[39min_memory)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/datasets/arrow_reader.py:329\u001b[0m, in \u001b[0;36mArrowReader.read_table\u001b[0;34m(filename, in_memory)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[39mRead table from file.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39m    pyarrow.Table\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    328\u001b[0m table_cls \u001b[39m=\u001b[39m InMemoryTable \u001b[39mif\u001b[39;00m in_memory \u001b[39melse\u001b[39;00m MemoryMappedTable\n\u001b[0;32m--> 329\u001b[0m \u001b[39mreturn\u001b[39;00m table_cls\u001b[39m.\u001b[39;49mfrom_file(filename)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/datasets/table.py:1018\u001b[0m, in \u001b[0;36mMemoryMappedTable.from_file\u001b[0;34m(cls, filename, replays)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1017\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mfrom_file\u001b[39m(\u001b[39mcls\u001b[39m, filename: \u001b[39mstr\u001b[39m, replays\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1018\u001b[0m     table \u001b[39m=\u001b[39m _memory_mapped_arrow_table_from_file(filename)\n\u001b[1;32m   1019\u001b[0m     table \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_apply_replays(table, replays)\n\u001b[1;32m   1020\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(table, filename, replays)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/datasets/table.py:64\u001b[0m, in \u001b[0;36m_memory_mapped_arrow_table_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_memory_mapped_arrow_table_from_file\u001b[39m(filename: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pa\u001b[39m.\u001b[39mTable:\n\u001b[0;32m---> 64\u001b[0m     opened_stream \u001b[39m=\u001b[39m _memory_mapped_record_batch_reader_from_file(filename)\n\u001b[1;32m     65\u001b[0m     pa_table \u001b[39m=\u001b[39m opened_stream\u001b[39m.\u001b[39mread_all()\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m pa_table\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/datasets/table.py:49\u001b[0m, in \u001b[0;36m_memory_mapped_record_batch_reader_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_memory_mapped_record_batch_reader_from_file\u001b[39m(filename: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pa\u001b[39m.\u001b[39mRecordBatchStreamReader:\n\u001b[0;32m---> 49\u001b[0m     memory_mapped_stream \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49mmemory_map(filename)\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mipc\u001b[39m.\u001b[39mopen_stream(memory_mapped_stream)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/pyarrow/io.pxi:1147\u001b[0m, in \u001b[0;36mpyarrow.lib.memory_map\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/pyarrow/io.pxi:1094\u001b[0m, in \u001b[0;36mpyarrow.lib.MemoryMappedFile._open\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/pyarrow/error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Failed to open local file '/srv/chawak/planning-with-llms/data/4_blocks/tokenized_dataset/val/data-00000-of-00001.arrow'. Detail: [errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "#verifying encoded file storage\n",
    "from datasets import Dataset\n",
    "split='val'\n",
    "# /srv/chawak/planning-with-llms/data/3_blocks/tokenized_dataset/test/\n",
    "ds= Dataset.from_file(f'/srv/chawak/planning-with-llms/data/{n}_blocks/tokenized_dataset/{split}/data-00000-of-00001.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=ds[0]['input_ids']\n",
    "decoded_text=tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>I am playing with a set of blocks where I need to arrange the blocks into stacks\n",
      "        Here are the actions I can do: Pick up a block, Unstack a block from on top of another block, Put down a block, Stack a block on top of another block.\n",
      "        I have the following restrictions on my actions:\n",
      "        I can only pick up or unstack one block at a time\n",
      "        I can only pick up or unstack a block if my hand is empty\n",
      "        I can only pick up a block if the block is on the table and the block is clear\n",
      "        A block is clear if the block has no other blocks on top of it and if the block is not picked up\n",
      "        I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block\n",
      "        I can only unstack a block from on top of another block if the block I am unstacking is clear\n",
      "        Once I pick up or unstack a block, I am holding the block\n",
      "        I can only put down a block that I am holding\n",
      "        I can only stack a block on top of another block if I am holding the block being stacked\n",
      "        I can only stack a block on top of another block if the block onto which I am stacking the block is clear\n",
      "        Once I put down or stack a block, my hand becomes empty\n",
      "        Once you stack a block on top of a second block, the second block is no longer clear\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the green block is clear,  the hand is empty, the red block is on the table, the pink block is on top of the red block, the green block is on top of the pink block.\n",
      "My goal is to have that  the green block is on the table, the red block is on top of the green block, the pink block is on top of the red block.\n",
      "\n",
      "My plan is as follows:\n",
      "\n",
      "[PLAN]\n",
      "unstack the green block from on top of the pink block\n",
      "put down the green block\n",
      "unstack the pink block from on top of the red block\n",
      "put down the pink block\n",
      "pick up the red block\n",
      "stack the red block on top of the green block\n",
      "pick up the pink block\n",
      "stack the pink block on top of the red block\n",
      "[PLAN END]\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the brown block is clear,  the hand is empty, the violet block is on the table, the teal block is on top of the violet block, the brown block is on top of the teal block.\n",
      "My goal is to have that  the violet block is on the table, the teal block is on the table, the brown block is on the table.\n",
      "\n",
      "My plan is as follows: \n",
      "\n",
      "[PLAN]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(decoded_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Define hyperparamters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from transformers import TrainingArguments, AdamW\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'gold_plan', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 99\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "n=3\n",
    "split='train'\n",
    "data_path=f'../data/{n}_blocks/tokenized_dataset/{split}'\n",
    "train_data=load_from_disk(data_path)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'gold_plan', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 15\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "n=3\n",
    "split='val'\n",
    "data_path=f'../data/{n}_blocks/tokenized_dataset/{split}'\n",
    "eval_data=load_from_disk(data_path)\n",
    "eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir='../results/SFT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#load model and tokenizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tokenizer\u001b[39m=\u001b[39mAutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(cfg[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m],cache_dir\u001b[39m=\u001b[39mcache_dir)\n\u001b[1;32m      3\u001b[0m model\u001b[39m=\u001b[39mAutoModelForCausalLM\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      4\u001b[0m     cfg[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[1;32m      6\u001b[0m     device_map\u001b[39m=\u001b[39mcfg[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdevice_map\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbfloat16\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "#load model and tokenizer\n",
    "tokenizer=AutoTokenizer.from_pretrained(cfg['model']['name'],cache_dir=cache_dir)\n",
    "model=AutoModelForCausalLM.from_pretrained(\n",
    "    cfg['model']['name'],\n",
    "    cache_dir=cache_dir,\n",
    "    device_map=cfg['model']['device_map'],\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset=Dataset.from_file(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get config file\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    cfg=yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LORA config \n",
    "peft_args=LoraConfig(\n",
    "    r=cfg['peft']['r'],\n",
    "    lora_alpha=cfg['peft']['lora_alpha'],\n",
    "    lora_dropout=cfg['peft']['lora_dropout'],\n",
    "    task_type=cfg['peft']['task_type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get LORA model\n",
    "lora_model=get_peft_model(model,peft_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_layers=lora_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fc3a9152f80>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args=SFTConfig(\n",
    "    output_dir=cfg['training']['output_dir']+f'/{n}_blocks',\n",
    "    num_train_epochs=cfg['training']['num_train_epochs'],\n",
    "    per_device_train_batch_size= cfg['training']['per_device_train_batch_size'],\n",
    "    gradient_accumulation_steps=cfg['training']['gradient_accumulation_steps'],\n",
    "    learning_rate=cfg['training']['learning_rate'],\n",
    "    weight_decay=cfg['training']['weight_decay'],\n",
    "    warmup_ratio=cfg['training']['warmup_ratio'],\n",
    "    #adam_epsilon=cfg['training']['adam_epsilon'],\n",
    "    #optim=cfg['training']['optim'],\n",
    "    logging_steps=cfg['training']['logging_steps'],\n",
    "    save_steps=cfg['training']['save_steps'],\n",
    "    eval_steps=cfg['training']['eval_steps'],\n",
    "    evaluation_strategy=cfg[\"training\"][\"evaluation_strategy\"],\n",
    "    save_strategy=cfg[\"training\"][\"save_strategy\"],\n",
    "    fp16=cfg[\"training\"][\"fp16\"],\n",
    "    bf16=cfg[\"training\"][\"bf16\"],\n",
    "    report_to=cfg[\"training\"][\"report_to\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer args dictionary\n",
    "optimizer = {\n",
    "    'params': lora_layers,\n",
    "    'lr': float(cfg['training']['learning_rate']),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=SFTTrainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_args,\n",
    "    optimizer_cls_and_kwargs=(AdamW,optimizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2164\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2165\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   2166\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   2167\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   2168\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   2169\u001b[0m     )\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/trainer.py:2524\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2517\u001b[0m context \u001b[39m=\u001b[39m (\n\u001b[1;32m   2518\u001b[0m     functools\u001b[39m.\u001b[39mpartial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mno_sync, model\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m   2519\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(batch_samples) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   2520\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mdistributed_type \u001b[39m!=\u001b[39m DistributedType\u001b[39m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2521\u001b[0m     \u001b[39melse\u001b[39;00m contextlib\u001b[39m.\u001b[39mnullcontext\n\u001b[1;32m   2522\u001b[0m )\n\u001b[1;32m   2523\u001b[0m \u001b[39mwith\u001b[39;00m context():\n\u001b[0;32m-> 2524\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2526\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2527\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2528\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2529\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2530\u001b[0m ):\n\u001b[1;32m   2531\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2532\u001b[0m     tr_loss \u001b[39m=\u001b[39m tr_loss \u001b[39m+\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/trainer.py:3654\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3651\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   3653\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3654\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs, num_items_in_batch\u001b[39m=\u001b[39;49mnum_items_in_batch)\n\u001b[1;32m   3656\u001b[0m \u001b[39mdel\u001b[39;00m inputs\n\u001b[1;32m   3657\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3658\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtorch_empty_cache_steps \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtorch_empty_cache_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   3660\u001b[0m ):\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:558\u001b[0m, in \u001b[0;36mSFTTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[39mCompute training loss and additionally compute token accuracies\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    557\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_evaluate \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 558\u001b[0m (loss, outputs) \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcompute_loss(\n\u001b[1;32m    559\u001b[0m     model, inputs, return_outputs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, num_items_in_batch\u001b[39m=\u001b[39;49mnum_items_in_batch\n\u001b[1;32m    560\u001b[0m )\n\u001b[1;32m    561\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    562\u001b[0m     \u001b[39m# When using padding-free, the attention_mask is not present in the inputs, instead we have cu_seq_lens_q,\u001b[39;00m\n\u001b[1;32m    563\u001b[0m     \u001b[39m# cu_seq_lens_k, and max_length_k, max_length_q and position_ids.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inputs:\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/trainer.py:3708\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3706\u001b[0m         loss_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_items_in_batch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3707\u001b[0m     inputs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3708\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   3709\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3710\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3711\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/accelerate/utils/operations.py:823\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mforward\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 823\u001b[0m     \u001b[39mreturn\u001b[39;00m model_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/accelerate/utils/operations.py:811\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 811\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_to_fp32(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdecorate_autocast\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[39mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/peft/peft_model.py:1756\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_peft_forward_hooks(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1755\u001b[0m         kwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1756\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_model(\n\u001b[1;32m   1757\u001b[0m             input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1758\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1759\u001b[0m             inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1760\u001b[0m             labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1761\u001b[0m             output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1762\u001b[0m             output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1763\u001b[0m             return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1764\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1765\u001b[0m         )\n\u001b[1;32m   1767\u001b[0m batch_size \u001b[39m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1768\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1769\u001b[0m     \u001b[39m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:193\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    171\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py:977\u001b[0m, in \u001b[0;36mGemma2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m    976\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 977\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m    978\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    979\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    980\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    981\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    982\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    983\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    984\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    985\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    986\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    987\u001b[0m     cache_position\u001b[39m=\u001b[39;49mcache_position,\n\u001b[1;32m    988\u001b[0m )\n\u001b[1;32m    990\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    991\u001b[0m \u001b[39m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py:763\u001b[0m, in \u001b[0;36mGemma2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    752\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    753\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    754\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m         cache_position,\n\u001b[1;32m    761\u001b[0m     )\n\u001b[1;32m    762\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 763\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    764\u001b[0m         hidden_states,\n\u001b[1;32m    765\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mcausal_mask,\n\u001b[1;32m    766\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    767\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    768\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    769\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    770\u001b[0m         cache_position\u001b[39m=\u001b[39;49mcache_position,\n\u001b[1;32m    771\u001b[0m     )\n\u001b[1;32m    773\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    775\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    171\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py:479\u001b[0m, in \u001b[0;36mGemma2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    476\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    478\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    480\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    481\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    482\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    483\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    484\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    485\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    486\u001b[0m     cache_position\u001b[39m=\u001b[39;49mcache_position,\n\u001b[1;32m    487\u001b[0m )\n\u001b[1;32m    488\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m    489\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49m_old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    171\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py:402\u001b[0m, in \u001b[0;36mGemma2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     attention_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_attn_implementation\n\u001b[0;32m--> 402\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m GEMMA2_ATTENTION_FUNCTION[attention_type](\n\u001b[1;32m    403\u001b[0m     \u001b[39mself\u001b[39;49m, query_states, key_states, value_states, attention_mask, output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    406\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mreshape(bsz, q_len, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    407\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mo_proj(attn_output)\n",
      "File \u001b[0;32m/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/models/gemma2/modeling_gemma2.py:196\u001b[0m, in \u001b[0;36meager_attention_forward\u001b[0;34m(config, query, key, value, mask, **_kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(attn_weights, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mto(query\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    195\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(attn_weights, p\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mattention_dropout, training\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m--> 196\u001b[0m attn_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(attn_weights, value_states)\n\u001b[1;32m    197\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    198\u001b[0m \u001b[39mreturn\u001b[39;00m attn_output, attn_weights\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Infer on the trained model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir='./results/SFT/3_blocks/checkpoint-12/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdcdc9791f04f048ba0f18a71633e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peft_config=PeftConfig.from_pretrained(cache_dir)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda:3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Gemma2ForCausalLM(\n",
       "      (model): Gemma2Model(\n",
       "        (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-41): 42 x Gemma2DecoderLayer(\n",
       "            (self_attn): Gemma2Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3584, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
       "              (rotary_emb): Gemma2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Gemma2MLP(\n",
       "              (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
       "              (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
       "              (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3584, out_features=256000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=PeftModel.from_pretrained(base_model,cache_dir)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer(prompt,return_tensors='pt').to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len=inputs['input_ids'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tokenizer(prompt, return_tensors='pt').to('cuda:3')\n",
    "#print(input_id.device_map)\n",
    "#print(model.device_map)\n",
    "\n",
    "response=model.generate(**inputs, max_new_tokens=32)\n",
    "#print(f'Response from LLM: {tokenizer.decode(response[0][input_len:],skip_special_tokens=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from LLM: [PLAN]\n",
      "unstack the brown block from on top of the teal block\n",
      "put down the brown block\n",
      "unstack the teal block from on top of the violet block\n",
      "put down the teal block\n",
      "[PLAN END]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs=model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0,\n",
    "    )\n",
    "print(f'Response from LLM: {tokenizer.decode(outputs[0][input_len:],skip_special_tokens=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='''I am playing with a set of blocks where I need to arrange the blocks into stacks\n",
    "        Here are the actions I can do: Pick up a block, Unstack a block from on top of another block, Put down a block, Stack a block on top of another block.\n",
    "        I have the following restrictions on my actions:\n",
    "        I can only pick up or unstack one block at a time\n",
    "        I can only pick up or unstack a block if my hand is empty\n",
    "        I can only pick up a block if the block is on the table and the block is clear\n",
    "        A block is clear if the block has no other blocks on top of it and if the block is not picked up\n",
    "        I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block\n",
    "        I can only unstack a block from on top of another block if the block I am unstacking is clear\n",
    "        Once I pick up or unstack a block, I am holding the block\n",
    "        I can only put down a block that I am holding\n",
    "        I can only stack a block on top of another block if I am holding the block being stacked\n",
    "        I can only stack a block on top of another block if the block onto which I am stacking the block is clear\n",
    "        Once I put down or stack a block, my hand becomes empty\n",
    "        Once you stack a block on top of a second block, the second block is no longer clear\n",
    "\n",
    "[STATEMENT]\n",
    "As initial conditions I have that, the green block is clear,  the hand is empty, the red block is on the table, the pink block is on top of the red block, the green block is on top of the pink block.\n",
    "My goal is to have that  the green block is on the table, the red block is on top of the green block, the pink block is on top of the red block.\n",
    "\n",
    "My plan is as follows:\n",
    "\n",
    "[PLAN]\n",
    "unstack the green block from on top of the pink block\n",
    "put down the green block\n",
    "unstack the pink block from on top of the red block\n",
    "put down the pink block\n",
    "pick up the red block\n",
    "stack the red block on top of the green block\n",
    "pick up the pink block\n",
    "stack the pink block on top of the red block\n",
    "[PLAN END]\n",
    "\n",
    "[STATEMENT]\n",
    "As initial conditions I have that, the brown block is clear,  the hand is empty, the violet block is on the table, the teal block is on top of the violet block, the brown block is on top of the teal block.\n",
    "My goal is to have that  the violet block is on the table, the teal block is on the table, the brown block is on the table.\n",
    "\n",
    "My plan is as follows: \n",
    "\n",
    "[PLAN]\n",
    "Answer within [PLAN] [PLAN END] tags.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planwllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
