{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/user/planning-with-llms/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from shared import llm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f09cb7f6b140f7bbb60ed8e07bbe3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model,tokenizer=llm_utils.get_model_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "#get config file\n",
    "with open(\"/home/user/planning-with-llms/src/rl/config.yaml\", \"r\") as f:\n",
    "    cfg=yaml.safe_load(f)\n",
    "\n",
    "peft_args=LoraConfig(\n",
    "    r=int(cfg['peft']['r']),\n",
    "    lora_alpha=int(cfg['peft']['lora_alpha']),\n",
    "    lora_dropout=float(cfg['peft']['lora_dropout']),\n",
    "    task_type=cfg['peft']['task_type'],\n",
    "    target_modules=list(cfg['peft']['target_modules']),\n",
    ")\n",
    "model=get_peft_model(model,peft_args)\n",
    "model.get_input_embeddings().weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define n,split\n",
    "n=3\n",
    "split='train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data-sample size is: 1\n"
     ]
    }
   ],
   "source": [
    "# data=PEFT_GRPO_trainer.main(3,'train')\n",
    "data_dir=f\"/home/user/planning-with-llms/data/{n}_blocks\"\n",
    "data_path=f'{data_dir}/GRPO_systhink_tokenized_dataset/{split}'\n",
    "data=load_from_disk(data_path)\n",
    "sample_size=1\n",
    "data=data.select(range(sample_size))\n",
    "print(f\"Data-sample size is: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "think='''I am a blocksworld plan generator.\n",
    "I first think about the reasoning process in the mind and then provide the user with the plan.\n",
    "The reasoning process and plan are enclosed within <think> </think> and [PLAN] [PLAN END] tags, respectively,\n",
    "i.e., <think> reasoning process here </think> [PLAN] plan here [PLAN END].'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=data[0]['input_ids']\n",
    "prompt=think+data[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt in the chat-template:<bos><start_of_turn>user\n",
      "I am a blocksworld plan generator.\n",
      "I first think about the reasoning process in the mind and then provide the user with the plan.\n",
      "The reasoning process and plan are enclosed within <think> </think> and [PLAN] [PLAN END] tags, respectively,\n",
      "i.e., <think> reasoning process here </think> [PLAN] plan here [PLAN END].I am playing with a set of blocks where I need to arrange the blocks into stacks\n",
      "        Here are the actions I can do: Pick up a block, Unstack a block from on top of another block, Put down a block, Stack a block on top of another block.\n",
      "        I have the following restrictions on my actions:\n",
      "        I can only pick up or unstack one block at a time\n",
      "        I can only pick up or unstack a block if my hand is empty\n",
      "        I can only pick up a block if the block is on the table and the block is clear\n",
      "        A block is clear if the block has no other blocks on top of it and if the block is not picked up\n",
      "        I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block\n",
      "        I can only unstack a block from on top of another block if the block I am unstacking is clear\n",
      "        Once I pick up or unstack a block, I am holding the block\n",
      "        I can only put down a block that I am holding\n",
      "        I can only stack a block on top of another block if I am holding the block being stacked\n",
      "        I can only stack a block on top of another block if the block onto which I am stacking the block is clear\n",
      "        Once I put down or stack a block, my hand becomes empty\n",
      "        Once you stack a block on top of a second block, the second block is no longer clear\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the brown block is clear, the teal block is clear,  the hand is empty, the violet block is on the table, the brown block is on top of the violet block, the teal block is on the table.\n",
      "My goal is to have that  the brown block is on the table, the violet block is on top of the brown block, the teal block is on top of the violet block.\n",
      "\n",
      "My plan is as follows:\n",
      "\n",
      "[PLAN]\n",
      "unstack the brown block from on top of the violet block\n",
      "put down the brown block\n",
      "pick up the violet block\n",
      "stack the violet block on top of the brown block\n",
      "pick up the teal block\n",
      "stack the teal block on top of the violet block\n",
      "[PLAN END]\n",
      "\n",
      "[STATEMENT]\n",
      "As initial conditions I have that, the green block is clear,  the hand is empty, the pink block is on the table, the red block is on top of the pink block, the green block is on top of the red block.\n",
      "My goal is to have that  the pink block is on the table, the red block is on top of the pink block, the green block is on the table.\n",
      "\n",
      "My plan is as follows: \n",
      "\n",
      "[PLAN]<end_of_turn>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_input,processor=llm_utils.get_tokenized_input(prompt=prompt,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_input = processor.decode(input, skip_special_tokens=True)\n",
    "# print(decoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=llm_utils.query_local_model(\n",
    "    tokenized_input=tokenized_input,\n",
    "    processor=processor,\n",
    "    model=model,\n",
    "    temperature=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "]\n",
      "model\n",
      "<think>\n",
      "Okay, let's analyze the problem. We have the green block on top of the red block, which is on top of the pink block. The green block is currently clear. The goal is to have the pink block on the table, the red block on top of the pink block, and the green block on the table.\n",
      "\n",
      "First, I need to get the green block off the red block. I can do this by unstacking the green block from the red block. Then, I need to put the green block down on the table. After that, I need to unstack the red block from the pink block, and then put the red block down on the table. Finally, the pink block will be on the table, the red block will be on the table, and the green block will be on the table, fulfilling the goal.\n",
      "\n",
      "</think>\n",
      "[PLAN]\n",
      "unstack the green block from on top of the red block\n",
      "put down the green block\n",
      "unstack the red block from on top of the pink block\n",
      "put down the red block\n",
      "[PLAN END]\n"
     ]
    }
   ],
   "source": [
    "print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
