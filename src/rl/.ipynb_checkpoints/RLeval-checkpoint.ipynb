{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting train result metrics ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/user/planning-with-llms/results/rl/training/\"\n",
    "#date=\"17_06/\"\n",
    "# date='debug-2006/'\n",
    "date=\"18_07/\"\n",
    "df= pd.read_csv(f'{path}{date}metrics.csv')\n",
    "#df=pd.read_csv(f\"{path}{inference_dir}\")\n",
    "df=df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Terminate']=df['Terminate'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminate_per_problem(lst, chunk_size):\n",
    "    return [sum(lst[i:i + chunk_size]) for i in range(0, len(lst), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"/home/user/planning-with-llms/src/rl/config.yaml\", \"r\") as f:\n",
    "    cfg=yaml.safe_load(f)\n",
    "group_size=cfg['training']['num_generations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Terminate_chunks'] = df['Terminate'].apply(lambda x: terminate_per_problem(x, group_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Terminate_chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "metrics = ['reward/format_reward', 'reward/plan_reward', 'reward/bonus_reward', '# Terminate']\n",
    "epochs = np.arange(len(df))\n",
    "bar_width = 0.2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    bar_positions = epochs + i * bar_width\n",
    "    values = df[metric]\n",
    "    \n",
    "    # Plot bars\n",
    "    bars = plt.bar(bar_positions, values, width=bar_width, label=metric)\n",
    "    \n",
    "    # Add value labels on top\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.3, f'{height:.1f}', \n",
    "                 ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# X-axis setup\n",
    "plt.xticks(epochs + bar_width * (len(metrics)-1)/2, [f'Epoch {i}' for i in epochs])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Epoch-wise rewards and #plans that reach goal')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "metrics = ['reward/format_reward', 'reward/plan_reward', 'reward/bonus_reward', '# Terminate']\n",
    "epochs = np.arange(len(df))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot a separate line for each metric\n",
    "for metric in metrics:\n",
    "    values = df[metric]\n",
    "    plt.plot(epochs, values, marker='o', label=metric)\n",
    "\n",
    "    # Add value labels at each point\n",
    "    for x, y in zip(epochs, values):\n",
    "        plt.text(x, y + 0.2, f'{y:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    #moving-average for plan-reward\n",
    "    if metric==\"reward/plan_reward\":\n",
    "        rolling_values=df[metric].rolling(window=3,min_periods=1).mean()\n",
    "        plt.plot(epochs,rolling_values,linestyle='--',linewidth=2, label= 'reward/plan_reward(rolling avg of 3)')\n",
    "\n",
    "# X-axis setup\n",
    "plt.xticks(epochs, [f'Epoch {i}' for i in epochs])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Epoch-wise rewards and #plans that reach goal')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrap for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response='''<think>\n",
    "\\nFirst unstack the green block from on top of the red block.\\n\n",
    "Then put down the green block.\\nThen pick up the red block.\\nThen stack the red block on top of the green block.\n",
    "\\nThen pick up the pink block.\\nThen stack the pink block on top of the red block.\\n\n",
    "</think>\n",
    "\\n[PLAN]\n",
    "\\nunstack the green block from on top of the red block\\nput down the green block\n",
    "\\npick up the red block\\nstack the red block on top of the green block\\npick up the pink block\n",
    "\\nstack the pink block on top of the red block\\n\n",
    "[PLAN END]\\n'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting info from logs ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/user//planning-with-llms/src/logs/\"\n",
    "#date=\"17_06/\"\n",
    "date='July/GRPO-train-1807.log'\n",
    "log_file = f\"{path}{date}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_path = log_file  # or use your variable\n",
    "target_pid = \"3457368\"\n",
    "# target_pid=\"3131681\"\n",
    "\n",
    "pid_usage = []\n",
    "timestamps = []\n",
    "\n",
    "with open(log_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "i = 0\n",
    "step = 0\n",
    "while i < len(lines):\n",
    "    if \"NVIDIA-SMI\" in lines[i]:\n",
    "        j = i\n",
    "        usage_this_block = 0\n",
    "        in_process_section = False\n",
    "\n",
    "        while j < len(lines):\n",
    "            line = lines[j].strip()\n",
    "\n",
    "            if line.startswith(\"| Processes:\"):\n",
    "                in_process_section = True\n",
    "\n",
    "            elif in_process_section:\n",
    "                # Look for a line containing the target PID\n",
    "                if re.search(rf\"\\|\\s+\\d+\\s+N/A\\s+N/A\\s+{target_pid}\\s+\", line):\n",
    "                    match = re.search(r\"(\\d+)MiB\", line)\n",
    "                    if match:\n",
    "                        mem = int(match.group(1))\n",
    "                        usage_this_block += mem\n",
    "                        print(f\"Step {step}: found {mem} MiB on this GPU\")\n",
    "\n",
    "                # End of the process table\n",
    "                if line.startswith(\"+-----------------------------------------------------------------------------------------+\"):\n",
    "                    break\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        if usage_this_block > 0:\n",
    "            pid_usage.append(usage_this_block)\n",
    "            timestamps.append(step)\n",
    "            step += 1\n",
    "\n",
    "        i = j\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "print(f\"Found {len(pid_usage)} data points for PID {target_pid}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamps, pid_usage, marker='o', label=f'PID {target_pid}')\n",
    "plt.xlabel(\"nvidia-smi snapshot index\")\n",
    "plt.ylabel(\"Memory Used (MiB)\")\n",
    "plt.title(f\"GPU Memory Usage Over Time for PID {target_pid}\")\n",
    "plt.grid(True)\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "for x in range(0, len(timestamps)+1, 15):\n",
    "    plt.axvline(x=x, linestyle=':', color='red', linewidth=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_path = log_file  # your full log file\n",
    "target_pid = \"3131681\"\n",
    "\n",
    "pid_usage = []\n",
    "timestamps = []\n",
    "\n",
    "with open(log_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "i = 0\n",
    "step = 0\n",
    "skip_next = False\n",
    "\n",
    "while i < len(lines):\n",
    "    if \"NVIDIA-SMI\" in lines[i]:\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        j = i\n",
    "        usage_this_block = 0\n",
    "        in_process_section = False\n",
    "\n",
    "        while j < len(lines):\n",
    "            line = lines[j].strip()\n",
    "\n",
    "            if line.startswith(\"| Processes:\"):\n",
    "                in_process_section = True\n",
    "\n",
    "            elif in_process_section:\n",
    "                if re.search(rf\"\\|\\s+\\d+\\s+N/A\\s+N/A\\s+{target_pid}\\s+\", line):\n",
    "                    match = re.search(r\"(\\d+)MiB\", line)\n",
    "                    if match:\n",
    "                        mem = int(match.group(1))\n",
    "                        usage_this_block += mem\n",
    "                        print(f\"Step {step}: found {mem} MiB on this GPU\")\n",
    "\n",
    "                if line.startswith(\"+-----------------------------------------------------------------------------------------+\"):\n",
    "                    break\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        if usage_this_block > 0:\n",
    "            pid_usage.append(usage_this_block)\n",
    "            timestamps.append(step)\n",
    "            step += 1\n",
    "\n",
    "        i = j + 1\n",
    "        skip_next = True  # skip next nvidia-smi block (the duplicate)\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "print(f\"Found {len(pid_usage)} data points for PID {target_pid}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamps, pid_usage, marker='o', label=f'PID {target_pid}')\n",
    "plt.xlabel(\"nvidia-smi snapshot index\")\n",
    "plt.ylabel(\"Memory Used (MiB)\")\n",
    "plt.title(f\"GPU Memory Usage Over Time for PID {target_pid}\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "for x in range(0, len(timestamps)+1, 15):\n",
    "    plt.axvline(x=x, linestyle=':', color='red', linewidth=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_path = log_file  # Change if needed\n",
    "\n",
    "total_gpu_usage = []\n",
    "timestamps = []\n",
    "\n",
    "with open(log_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "i = 0\n",
    "step = 0\n",
    "\n",
    "while i < len(lines):\n",
    "    if \"NVIDIA-SMI\" in lines[i]:\n",
    "        j = i\n",
    "        usage_this_block = 0\n",
    "        found_usage = False\n",
    "\n",
    "        while j < len(lines):\n",
    "            line = lines[j].strip()\n",
    "\n",
    "            # Match the usage line: |  27595MiB / 81559MiB |\n",
    "            match = re.search(r\"\\|\\s+(\\d+)MiB\\s+/\\s+\\d+MiB\\s+\\|\", line)\n",
    "            if match:\n",
    "                mem = int(match.group(1))\n",
    "                usage_this_block += mem\n",
    "                found_usage = True\n",
    "\n",
    "            if line.startswith(\"+---------------------------------------------------------------------------------------+\"):\n",
    "                break\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        if found_usage:\n",
    "            total_gpu_usage.append(usage_this_block)\n",
    "            timestamps.append(step)\n",
    "            print(f\"Step {step}: Total GPU usage = {usage_this_block} MiB\")\n",
    "            step += 1\n",
    "\n",
    "        i = j\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "print(f\"\\n✅ Found {len(total_gpu_usage)} data points.\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamps, total_gpu_usage, marker='o')\n",
    "plt.xlabel(\"nvidia-smi snapshot index\")\n",
    "plt.ylabel(\"Total GPU Memory Used (MiB)\")\n",
    "plt.title(\"Total GPU Memory Usage Over Time\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "for x in range(0, len(timestamps)+1, 15):\n",
    "    plt.axvline(x=x, linestyle=':', color='red', linewidth=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK QUERY LOCAL MODEL #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/user/planning-with-llms/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl import PEFT_GRPO_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared import llm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=PEFT_GRPO_trainer.peft_model\n",
    "tokenizer=PEFT_GRPO_trainer.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "# # from datasets import concatenate_datasets\n",
    "# from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# #get config file\n",
    "# with open(\"/home/user/planning-with-llms/src/rl/config.yaml\", \"r\") as f:\n",
    "#     cfg=yaml.safe_load(f)\n",
    "\n",
    "# peft_args=LoraConfig(\n",
    "#     r=int(cfg['peft']['r']),\n",
    "#     lora_alpha=int(cfg['peft']['lora_alpha']),\n",
    "#     lora_dropout=float(cfg['peft']['lora_dropout']),\n",
    "#     task_type=cfg['peft']['task_type'],\n",
    "#     target_modules=list(cfg['peft']['target_modules']),\n",
    "# )\n",
    "# peft_model=get_peft_model(model,peft_args)\n",
    "# peft_model.get_input_embeddings().weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=PEFT_GRPO_trainer.main(3,'train')\n",
    "sample_size=1\n",
    "data=data.select(range(sample_size))\n",
    "print(f\"Data-sample size is: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "think='''I am a blocksworld plan generator.\n",
    "I first think about the reasoning process in the mind and then provide the user with the plan.\n",
    "The reasoning process and plan are enclosed within <think> </think> and [PLAN] [PLAN END] tags, respectively,\n",
    "i.e., <think> reasoning process here </think> [PLAN] plan here [PLAN END].'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=data[0]['input_ids']\n",
    "prompt=think+data[0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input,processor=llm_utils.get_tokenized_input(prompt=prompt,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_input = processor.decode(input, skip_special_tokens=True)\n",
    "print(decoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l=tokenized_input['input_ids'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_tokenized_input= p.decode(tokenized_input[\"input_ids\"][0], skip_special_tokens=True)\n",
    "# print(decoded_tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=llm_utils.query_local_model(\n",
    "    tokenized_input=tokenized_input,\n",
    "    processor=p,\n",
    "    model=model,\n",
    "    temperature=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planwllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
