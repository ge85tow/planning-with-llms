{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/srv/chawak/planning-with-llms/results/rl/training/\"\n",
    "#date=\"17_06/\"\n",
    "# date='debug-2006/'\n",
    "date=\"09_07/\"\n",
    "df= pd.read_csv(f'{path}{date}metrics.csv')\n",
    "#df=pd.read_csv(f\"{path}{inference_dir}\")\n",
    "df=df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Terminate']=df['Terminate'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminate_per_problem(lst, chunk_size):\n",
    "    return [sum(lst[i:i + chunk_size]) for i in range(0, len(lst), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"/srv/chawak/planning-with-llms/src/rl/config.yaml\", \"r\") as f:\n",
    "    cfg=yaml.safe_load(f)\n",
    "group_size=cfg['training']['num_generations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Terminate_chunks'] = df['Terminate'].apply(lambda x: terminate_per_problem(x, group_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Terminate_chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "metrics = ['reward/format_reward', 'reward/plan_reward', 'reward/bonus_reward', '# Terminate']\n",
    "epochs = np.arange(len(df))\n",
    "bar_width = 0.2\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    bar_positions = epochs + i * bar_width\n",
    "    values = df[metric]\n",
    "    \n",
    "    # Plot bars\n",
    "    bars = plt.bar(bar_positions, values, width=bar_width, label=metric)\n",
    "    \n",
    "    # Add value labels on top\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.3, f'{height:.1f}', \n",
    "                 ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# X-axis setup\n",
    "plt.xticks(epochs + bar_width * (len(metrics)-1)/2, [f'Epoch {i}' for i in epochs])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Epoch-wise rewards and #plans that reach goal')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "metrics = ['reward/format_reward', 'reward/plan_reward', 'reward/bonus_reward', '# Terminate']\n",
    "epochs = np.arange(len(df))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot a separate line for each metric\n",
    "for metric in metrics:\n",
    "    values = df[metric]\n",
    "    plt.plot(epochs, values, marker='o', label=metric)\n",
    "\n",
    "    # Add value labels at each point\n",
    "    for x, y in zip(epochs, values):\n",
    "        plt.text(x, y + 0.2, f'{y:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    #moving-average for plan-reward\n",
    "    if metric==\"reward/plan_reward\":\n",
    "        rolling_values=df[metric].rolling(window=3,min_periods=1).mean()\n",
    "        plt.plot(epochs,rolling_values,linestyle='--',linewidth=2, label= 'reward/plan_reward(rolling avg of 3)')\n",
    "\n",
    "# X-axis setup\n",
    "plt.xticks(epochs, [f'Epoch {i}' for i in epochs])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Epoch-wise rewards and #plans that reach goal')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrap for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gibberish=r\"(.*)\"\n",
    "plan=r\"\\[PLAN\\](.*?)\\[PLAN END\\]\"\n",
    "think=r\"<think>(.*?)<\\/think>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case-1: no gibberish, no plan, yes think \n",
    "pattern1=f\"{think}\"\n",
    "compiled1=re.compile(pattern1,re.DOTALL)\n",
    "\n",
    "#case-2: no gibberish, yes plan, no think\n",
    "pattern2=f\"{plan}\"\n",
    "compiled2=re.compile(pattern2,re.DOTALL)\n",
    "\n",
    "#case-3: no gibberish, yes plan, yes think\n",
    "pattern3=f\"{think}\\s*{plan}\"\n",
    "compiled3=re.compile(pattern3,re.DOTALL)\n",
    "\n",
    "#case-6: yes gibberish, yes plan, yes think\n",
    "pattern6=f\"{think}{gibberish}{plan}\"\n",
    "compiled6=re.compile(pattern6,re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_func(response):\n",
    "    \n",
    "    response=response.strip()\n",
    "    score=0\n",
    "\n",
    "    #ONLY think tag\n",
    "    fullmatchthink=False\n",
    "    if compiled1.fullmatch(response):\n",
    "        score=7\n",
    "        fullmatchthink=True\n",
    "    if compiled1.search(response) and not fullmatchthink:\n",
    "        score=5\n",
    "    \n",
    "    #ONLY plan tag\n",
    "    fullmatchplan=False\n",
    "    if compiled2.fullmatch(response):\n",
    "        score=3\n",
    "        fullmatchplan=True\n",
    "    if compiled2.search(response) and not fullmatchplan:\n",
    "        score=2\n",
    "    \n",
    "    #COMBO of both tags\n",
    "    fullmatchcombo=False\n",
    "    if compiled3.fullmatch(response):\n",
    "        score=20\n",
    "        fullmatchcombo=True\n",
    "    if compiled6.search(response) and not fullmatchcombo:\n",
    "        score=15\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response='''<think>\n",
    "\\nFirst unstack the green block from on top of the red block.\\n\n",
    "Then put down the green block.\\nThen pick up the red block.\\nThen stack the red block on top of the green block.\n",
    "\\nThen pick up the pink block.\\nThen stack the pink block on top of the red block.\\n\n",
    "</think>\n",
    "\\n[PLAN]\n",
    "\\nunstack the green block from on top of the red block\\nput down the green block\n",
    "\\npick up the red block\\nstack the red block on top of the green block\\npick up the pink block\n",
    "\\nstack the pink block on top of the red block\\n\n",
    "[PLAN END]\\n'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response='''<think>\n",
    "\\nFirst unstack the green block from on top of the red block.\\n\n",
    "Then put down the green block.\\nThen pick up the red block.\\nThen stack the red block on top of the green block.\n",
    "\\nThen pick up the pink block.\\nThen stack the pink block on top of the red block.\\n\n",
    "</think>\n",
    "\\n[PLAN]\n",
    "\\nunstack the green block from on top of the red block\\nput down the green block\n",
    "\\npick up the red block\\nstack the red block on top of the green block\\npick up the pink block\n",
    "\\nstack the pink block on top of the red block\\n\n",
    "[PLAN END]\\n\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_func(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/srv/chawak/planning-with-llms/src/logs/\"\n",
    "#date=\"17_06/\"\n",
    "date='July/GRPO-train-1107.log'\n",
    "log_file = f\"{path}{date}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_path = log_file  # or use your variable\n",
    "target_pid = \"3457368\"\n",
    "# target_pid=\"3131681\"\n",
    "\n",
    "pid_usage = []\n",
    "timestamps = []\n",
    "\n",
    "with open(log_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "i = 0\n",
    "step = 0\n",
    "while i < len(lines):\n",
    "    if \"NVIDIA-SMI\" in lines[i]:\n",
    "        j = i\n",
    "        usage_this_block = 0\n",
    "        in_process_section = False\n",
    "\n",
    "        while j < len(lines):\n",
    "            line = lines[j].strip()\n",
    "\n",
    "            if line.startswith(\"| Processes:\"):\n",
    "                in_process_section = True\n",
    "\n",
    "            elif in_process_section:\n",
    "                # Look for a line containing the target PID\n",
    "                if re.search(rf\"\\|\\s+\\d+\\s+N/A\\s+N/A\\s+{target_pid}\\s+\", line):\n",
    "                    match = re.search(r\"(\\d+)MiB\", line)\n",
    "                    if match:\n",
    "                        mem = int(match.group(1))\n",
    "                        usage_this_block += mem\n",
    "                        print(f\"Step {step}: found {mem} MiB on this GPU\")\n",
    "\n",
    "                # End of the process table\n",
    "                if line.startswith(\"+-----------------------------------------------------------------------------------------+\"):\n",
    "                    break\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        if usage_this_block > 0:\n",
    "            pid_usage.append(usage_this_block)\n",
    "            timestamps.append(step)\n",
    "            step += 1\n",
    "\n",
    "        i = j\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "print(f\"Found {len(pid_usage)} data points for PID {target_pid}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamps, pid_usage, marker='o', label=f'PID {target_pid}')\n",
    "plt.xlabel(\"nvidia-smi snapshot index\")\n",
    "plt.ylabel(\"Memory Used (MiB)\")\n",
    "plt.title(f\"GPU Memory Usage Over Time for PID {target_pid}\")\n",
    "plt.grid(True)\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "for x in range(0, len(timestamps)+1, 15):\n",
    "    plt.axvline(x=x, linestyle=':', color='red', linewidth=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_path = log_file  # your full log file\n",
    "target_pid = \"3131681\"\n",
    "\n",
    "pid_usage = []\n",
    "timestamps = []\n",
    "\n",
    "with open(log_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "i = 0\n",
    "step = 0\n",
    "skip_next = False\n",
    "\n",
    "while i < len(lines):\n",
    "    if \"NVIDIA-SMI\" in lines[i]:\n",
    "        if skip_next:\n",
    "            skip_next = False\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        j = i\n",
    "        usage_this_block = 0\n",
    "        in_process_section = False\n",
    "\n",
    "        while j < len(lines):\n",
    "            line = lines[j].strip()\n",
    "\n",
    "            if line.startswith(\"| Processes:\"):\n",
    "                in_process_section = True\n",
    "\n",
    "            elif in_process_section:\n",
    "                if re.search(rf\"\\|\\s+\\d+\\s+N/A\\s+N/A\\s+{target_pid}\\s+\", line):\n",
    "                    match = re.search(r\"(\\d+)MiB\", line)\n",
    "                    if match:\n",
    "                        mem = int(match.group(1))\n",
    "                        usage_this_block += mem\n",
    "                        print(f\"Step {step}: found {mem} MiB on this GPU\")\n",
    "\n",
    "                if line.startswith(\"+-----------------------------------------------------------------------------------------+\"):\n",
    "                    break\n",
    "\n",
    "            j += 1\n",
    "\n",
    "        if usage_this_block > 0:\n",
    "            pid_usage.append(usage_this_block)\n",
    "            timestamps.append(step)\n",
    "            step += 1\n",
    "\n",
    "        i = j + 1\n",
    "        skip_next = True  # skip next nvidia-smi block (the duplicate)\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "print(f\"Found {len(pid_usage)} data points for PID {target_pid}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamps, pid_usage, marker='o', label=f'PID {target_pid}')\n",
    "plt.xlabel(\"nvidia-smi snapshot index\")\n",
    "plt.ylabel(\"Memory Used (MiB)\")\n",
    "plt.title(f\"GPU Memory Usage Over Time for PID {target_pid}\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "for x in range(0, len(timestamps)+1, 15):\n",
    "    plt.axvline(x=x, linestyle=':', color='red', linewidth=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu1_usage[:53]=[g-17246 for g in gpu1_usage[:53]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu1_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "if gpu1_usage:\n",
    "    plt.plot(timestamps[:len(gpu1_usage)], gpu1_usage, label=\"GPU 1\", marker=\"o\")\n",
    "if gpu2_usage:\n",
    "    plt.plot(timestamps[:len(gpu2_usage)], gpu2_usage, label=\"GPU 2\", marker=\"o\")\n",
    "plt.xlabel(\"model update step\")\n",
    "plt.ylabel(\"Memory Used (MiB)\")\n",
    "plt.title(\"GPU Memory Usage Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import verl\n",
    "print(verl.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import verl.trainer\n",
    "print(dir(verl.trainer))\n",
    "import verl.trainer.ppo\n",
    "print(dir(verl.trainer.ppo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planwllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
