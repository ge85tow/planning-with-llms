
model:
  name: google/gemma-3-12b-it
  device_map: auto

training:
  num_train_epochs: 250
  per_device_train_batch_size: 2 #1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 8 #128
  learning_rate: 1e-5
  weight_decay: 0.01
  warmup_ratio: 0 #OG: 0.1
  lr_scheduler_type: cosine #linear
  optim: 'adamw_torch'
  adam_epsilon: 1e-8
#logging and saving
  output_dir: /srv/chawak/planning-with-llms/results/SFT/training/training_11-06
  evaluation_strategy: epoch
  logging_strategy: epoch
  save_strategy: steps
  save_steps: 2280
  bf16: true
  fp16: false
  report_to: tensorboard


peft:
  r: 32
  lora_alpha: 64
  lora_dropout: 0.05
  task_type: "CAUSAL_LM"
  target_modules: ['q_proj','v_proj','k_proj','o_proj','gate_proj','up_proj','down_proj'] #decrease # layers keep: qvko

adalora:
  peft_type: "ADALORA"
  task_type: "CAUSAL_LM"
  init_r: 64
  target_r: 32
  lora_alpha: 128
  target_modules: ['q_proj','v_proj','k_proj','o_proj','gate_proj','up_proj','down_proj']
  lora_dropout: 0.05

oft:
  peft_type: "OFT"
  r: 64
  init_weights: True
  module_dropout: 0.0
  task_type: "CAUSAL_LM"
  target_modules: ['q_proj','v_proj','k_proj','o_proj','gate_proj','up_proj','down_proj']
