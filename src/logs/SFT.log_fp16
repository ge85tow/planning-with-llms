nohup: ignoring input
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:00<00:03,  1.06it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:01<00:00,  6.11it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:01<00:00,  4.75it/s]
Some parameters are on the meta device because they were offloaded to the cpu.
trainable params: 68,070,912 || all params: 12,255,395,952 || trainable%: 0.5554
Printing trainable model parameters : None
Traceback (most recent call last):
  File "/srv/chawak/planning-with-llms/src/SFT.py", line 76, in <module>
    trainer=SFTTrainer(
            ^^^^^^^^^^^
  File "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/trl/trainer/sft_trainer.py", line 321, in __init__
    super().__init__(
  File "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/trainer.py", line 621, in __init__
    self._move_model_to_device(model, args.device)
  File "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/transformers/trainer.py", line 904, in _move_model_to_device
    model = model.to(device)
            ^^^^^^^^^^^^^^^^
  File "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1343, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  [Previous line repeated 6 more times]
  File "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 930, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/srv/chawak/envs/planwllm/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1336, in convert
    raise NotImplementedError(
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
